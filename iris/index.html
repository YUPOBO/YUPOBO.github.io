<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <title>Instance-Level Object Reconstruction in Scenes based on Key-point Diffusion Model</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            min-height: 100vh;
            margin: 0;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        .container {
            text-align: center;
            background-color: #fff;
            padding: 20px;
            margin-top: 50px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            max-width: 1100px;
            width: 100%;
        }
        .title {
            font-size: 28px;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .author {
            font-size: 18px;
            margin-bottom: 20px;
        }
        .author a {
            text-decoration: none;
            color: #0073e6;
        }
        .author a:hover {
            text-decoration: underline;
        }
        .image-container {
            margin-top: 20px;
        }
        .image-container img {
            width: 85%; /* Adjust this to control the image width relative to the container */
            max-width: 900px; /* Ensure the image does not get too large */
            height: auto;
            border-radius: 8px;
            margin-top: 20px;
        }
        .words-container {
            text-align: center;
            width: 85%;
            margin-top: 10px;
            margin-left: auto;
            margin-right: auto;
        }
        .words-container .justified-text {
            text-align: justify;
            margin-bottom: 8px;
        }
        .words-container .small-title {
            font-size: 17px;
            margin-bottom: 5px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="title">Instance-Level Object Reconstruction in Scenes based on Key-point Diffusion Model</div>
        <div class="author">
            <a href="https://scholar.google.com/citations?user=9GbfsdwAAAAJ&hl=zh-CN">Xibo Fan</a>
        </div>
        <div class="image-container">
            <img src="source/img/teaser.png" alt="Description of the image">
        </div>

        <div class="words-container">
            <div class="small-title">Abstract</div>
            <div class="justified-text">
                Semantic scene reconstruction based on point clouds is an important and challenging task in 3D scene understanding. This task requires not only identifying each instance in the point cloud scene but also reconstructing their geometric shapes based on partially observed point cloud data. 
            </div>
            <div class="justified-text">
                Compared to previous work, the algorithm of this work addresses issues such as the significant impact of predicted pose on reconstruction results, poor quality and insufficient quantity of supervised data during partial cloud reconstruction, unreasonable utilization of predicted partial point clouds, and limited expression ability of previous reconstruction methods.Furthermore, we address data quality issues by improving the acquisition and utilization of keypoint features. Moreover, we enhance the reconstruction quality of incomplete point clouds by incorporating keypoints into a diffusion model.
            </div>
        </div>

        

        <div class="words-container">
            <div class="small-title">Method</div>
            <div class="justified-text">
                The algorithm is mainly divided into three parts, namely three models.
            </div>
        </div>

        <div class="image-container">
            <img src="source/img/method.png" alt="Description of the image">
        </div>

        <div class="words-container">
            <div class="justified-text">
                The algorithm is mainly divided into three parts, namely three models.
            </div>
            <div class="justified-text">
                "The Mask3D Based Object Segmentation & Localization Prediction" part requires segmenting the point cloud of the object from the scene point cloud and obtaining corresponding pose information. This section is modified based on the Mask3D segmentation model to predict the center and size of the object, but not the angle.
            </div>
            <div class="justified-text">
            "Shape Prior Vae"  embeds the shape of a 3D object into latent vectors, representing the object using latent vectors. At this step,  data augmentation will be performed during training, where the orientation of the object is arbitrary, allowing the reconstruction method to handle input of point cloud objects with any orientation. We use keypoints and overall points to do cross attention, which makes it faster and more effective to obtain Key Points Features for future use.
            </div>
            <div class="justified-text">
            "Partial Point Cloud Reconstruction Diffusion Model" requires training a key point diffusion model to complete and reconstruct the partial point clouds. During training, the scene point cloud segmentation detection model is used to obtain the partial point cloud and pose information of the instance, which is then transformed from the scene space to the regular space as input for the key point diffusion model.
            </div>
        </div>

        <script>

            var scene = new THREE.Scene();
            var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            var renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);
    

            var light = new THREE.PointLight(0xffffff, 1);
            light.position.set(1, 1, 1);
            scene.add(light);
    

            var controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.25;
            controls.enableZoom = true;
    

            function loadOBJ(scene, filePath, position) {
                var loader = new THREE.OBJLoader();
                loader.load(
                    filePath,
                    function (object) {
                        object.position.set(position.x, position.y, position.z);
                        scene.add(object);
                    },
                    function (xhr) {
                        console.log((xhr.loaded / xhr.total * 100) + '% 已加载');
                    },
                    function (error) {
                        console.log('加载错误：', error);
                    }
                );
            }
    

            function animate() {
                requestAnimationFrame(animate);
                controls.update();
                renderer.render(scene, camera);
            }
    

            camera.position.z = 5;
    


            loadOBJ(scene, 'source/3d/scene0549_00.obj', { x: -2, y: 0, z: 0 });
            loadOBJ(scene, 'source/3d/549_dimr.obj', { x: 0, y: 0, z: 0 });
            loadOBJ(scene, 'source/3d/549_bi0.obj', { x: 2, y: 0, z: 0 });
            loadOBJ(scene, 'source/3d/549_gt.obj', { x: 4, y: 0, z: 0 });
    

            animate();
        </script>




    </div>
</body>
</html>